# MultiHipPoseNet

This is a pytorch implementation of MultiHipPoseNet, a multitasking model for structure segmentation and keypoint detection

![](https://github.com/Starsm7/MultiHipPoseNet/blob/main/nets/schematic illustration.png)

The schematic illustration of the MuiltHipPoseNet algorithm. Firstly, hip joint ultrasound images are fed into the network, followed by feature extraction utilizing the multi-expert gated channel transformation unit, ME-GCT. Next, the feature maps generated from the structure and landmark detection branches are sent to the multi-task graph adaptive learning mechanism, MT-GALM. Finally, we derive seven estimated mask markings and six predicted landmarks from the detection branches for DDH analysis. 

ME-GCT, a multi-expert gated channel transformation unit, could model the relationships between tasks and channels utilizing the combination of multiple experts' channel weights and maximize overall performance.  MT-YAML represents a multi-task graph adaptive learning mechanism, which enables the mining of hidden dynamic dependencies between adjacent channels in various tasks, thereby reducing the risk of model overfitting on a single task and improving model robustness. 

![](https://github.com/Starsm7/MultiHipPoseNet/blob/main/nets/ME-GCT_MT-GALM.png)

Illustration of ME-GCT and MT-YAML. $\bigotimes$ represents the weighted combination of multi-expert channels, while $\bigodot$ represents the addition of task features and information-gain features. For example, in task 1, the initial task features are generated by integrating various combinations of multi-expert channel weights. Subsequently, the feature slices, represented as nodes, are learned through a graph neural network to extract the information-gain features relevant to task 1 (green square) from other tasks (blue square). Ultimately, this results in features that not only encompass the characteristics of task 1 but also capture the implicit dependencies with other tasks. The same methodology is applied to task 2. 

We collecte hip US images of 781 infants aged 0-6 months. Each patient contains one or two images of the left and right legs, for 1355 images. The images include 568 infants with type I hips without dislocation and 213 infants with type II hips.

## Requirements

* PyTorch
* scikit-learn
* numpy
* labelme == 3.16.5

## Usage

We provide several python scripts that contain functions for data processing, dividing, training, prediction, and evaluation. These scripts must be run in the following order:

1. json_to_dataset.py - Converts json files labeled with labelme into masked png files.
2. voc_annotation.py - Hierarchical cross-validation divides the data into training, validation, and test sets.
3. train.py - training file, click on it to train the model, optionally with or without ME-GCT.
4. predict.py - test file, perform inference evaluation on the training model (5-fold hierarchical validation), optionally with or without visualization of mask and coordinate prediction results.
5. eval.py - A set of evaluation metrics to calculate the results of the model evaluation.

## Acknowledgements

This project utilizes parts of [Bubbliiiing](https://github.com/Bubbliiiing)'s [unet-pytorch](https://github.com/bubbliiiing/unet-pytorch) and includes modifications and improvements made by us. We thank them for their excellent work.

## Issues/Pull Requests/Feedbacks

Don't hesitate to contact for any feedback or create issues/pull requests/feedbacks.
